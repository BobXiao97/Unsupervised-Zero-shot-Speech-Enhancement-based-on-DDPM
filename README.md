# Unsupervised Zero-shot Speech Enhancement based on DDPM
 This is the implementation of my master's thesis.  
 Preprocess_mel.py is to convert audio from waveform to Mel-spectrogram.  
 Diffusion_mel.py uses the processed data from preprocess_mel.py to train the model.  
 Test.py is to generate results using the model obtained from diffusion_mel.py.  
 You will need to adjust the paths accordingly.  
 The sample folder contains some output generated using this model. Here are a few for your convenience.  


https://github.com/BobXiao97/Unsupervised-Zero-shot-Speech-Enhancement-based-on-DDPM/assets/56871452/10fb294a-c972-49c9-a5d4-abc5acc38213



https://github.com/BobXiao97/Unsupervised-Zero-shot-Speech-Enhancement-based-on-DDPM/assets/56871452/930bb142-5d6c-4866-a508-7e3d621fb29e



https://github.com/BobXiao97/Unsupervised-Zero-shot-Speech-Enhancement-based-on-DDPM/assets/56871452/dccebd14-d17a-49a5-b131-5088c757cd61



https://github.com/BobXiao97/Unsupervised-Zero-shot-Speech-Enhancement-based-on-DDPM/assets/56871452/ccd70209-a2db-4edb-83f6-3743074b8159



https://github.com/BobXiao97/Unsupervised-Zero-shot-Speech-Enhancement-based-on-DDPM/assets/56871452/93307adc-af8f-42e0-a8c5-661e7f5fdb64

