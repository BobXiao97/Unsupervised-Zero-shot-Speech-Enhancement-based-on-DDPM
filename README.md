# Unsupervised Zero-shot Speech Enhancement based on DDPM
 This is the implementation of my master's thesis.  
 Preprocess_mel.py is to convert audio from waveform to Mel-spectrogram.  
 Diffusion_mel.py uses the processed data from preprocess_mel.py to train the model.  
 Test.py is to generate results using the model obtained from diffusion_mel.py.  
 You will need to adjust the paths accordingly.  
 The sample folder contains some output generated using this model.

