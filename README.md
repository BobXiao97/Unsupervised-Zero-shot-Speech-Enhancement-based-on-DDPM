# Unsupervised Zero-shot Speech Enhancement based on DDPM
 This is the implementation of my master's thesis. 
 preprocess_mel.py is to convert audio from waveform to Mel-spectrogram.
 diffusion_mel.py uses the processed data from preprocess_mel.py to train the model.
 test.py is to generate results using the model obtained from diffusion_mel.py.
 You will need to adjust the paths accordingly.
 The sample folder contains some output generated using this model.
